# Ответы на вопросы по курсу "Компьютерное зрение и обработка изображений"

## Модуль 1. Цифровое изображение и базовая обработка

### 1. Определение, физический и логический пиксель
**Цифровое изображение** — это двумерная функция $f(x, y)$, где $x$ и $y$ — пространственные координаты, а значение функции в любой точке пропорционально яркости (или цвету) сцены. В цифровом виде это массив (матрица) чисел.

* **Физический пиксель:** Наименьший управляемый элемент матрицы дисплея или сенсора камеры. Это «железо».
* **Логический пиксель:** Абстрактная единица измерения, используемая в программном обеспечении (CSS в вебе, координаты UI).
* **Почему это важно:** На современных экранах (HiDPI/Retina) один логический пиксель может состоять из 4 (2x2) или более физических пикселей. Если игнорировать это различие при обработке, изображение может выглядеть мыльным (при растягивании) или слишком мелким (если отображать «пиксель в пиксель»).

### 2. Разрешение, DPI/PPI и глубина цвета
* **Разрешение (Resolution):** Количество пикселей по ширине и высоте (например, 1920×1080). Определяет максимальную детализацию, которую *принципиально* может передать изображение.
* **DPI/PPI (Dots/Pixels Per Inch):** Плотность пикселей. Связывает цифровое разрешение с физическим размером при печати или отображении. Высокий PPI делает изображение четким для глаза, низкий — зернистым («пикселизация»).
* **Глубина цвета (Bit Depth):** Количество бит, отведенных на хранение цвета одного пикселя (например, 8 бит на канал = 256 оттенков).
    * *Влияние:* Низкая глубина цвета приводит к артефактам **бандинга** (ступенчатые градиенты), так как не хватает оттенков для плавного перехода. Высокая глубина (10-12 бит) увеличивает объём данных, но необходима для профессиональной цветокоррекции и HDR.

### 3. Глаз vs Цифровая камера
* **Сенсор:** Глаз использует сетчатку с фоторецепторами (палочки — для ночного зрения, колбочки — для цвета). Камера использует матрицу (CMOS/CCD) с фильтром Байера (обычно) для получения цвета.
* **Адаптация (Dynamic Range):**
    * *Глаз:* Логарифмическая чувствительность. Мы одновременно видим детали в ярком небе и в глубокой тени.
    * *Камера:* Линейная чувствительность. Сенсор просто считает фотоны. Без обработки (гамма-коррекции) снимки выглядят темными, а динамический диапазон уже, чем у глаза (риск засветов или провалов в черноту).
* **Цветопередача:** Глаз адаптируется к источнику света (автоматический баланс белого мозга), камера требует настройки (иначе при лампах накаливания всё будет желтым).

### 4. Дискретизация
* **По пространству (Sampling):** Преобразование непрерывной сцены в сетку пикселей.
    * *Артефакты:* Если частота дискретизации ниже частоты деталей (Теорема Котельникова/Найквиста), возникает **aliasing** («лесенки» на наклонных линиях) или **муар** (интерференционные узоры на мелких текстурах, например, на ткани).
* **По яркости (Quantization):** Преобразование непрерывной яркости в дискретные уровни (0–255).
    * *Артефакты:* **Постеризация** или ложные контуры — когда вместо плавного градиента видны полосы одного цвета.

### 5. Цветовые модели
* **RGB (Red, Green, Blue):** Аддитивная модель. Координаты — интенсивности излучателей.
    * *Применение:* Мониторы, сенсоры камер. Неудобна для анализа, так как яркость и цвет сильно коррелируют (изменение освещения меняет все три компоненты R, G, B).
* **HSI/HSV (Hue, Saturation, Intensity/Value):** Делит цвет на Тон, Насыщенность и Яркость.
    * *Применение:* Идеальна для цветовой сегментации («найти красный объект независимо от того, в тени он или на свету» — достаточно ограничить Hue).
* **CIE XYZ / Lab:** Перцептивно-равномерные модели, основанные на восприятии человека. В Lab расстояние между цветами (евклидово) соответствует разнице, видимой глазом.
    * *Применение:* Профессиональная цветокоррекция, сравнение точности цветопередачи ($\Delta E$).

### 6. Свёртка и корреляция
* **Свёртка (Convolution):** Математическая операция, где ядро (фильтр) сначала **зеркально отражается** относительно центра, а затем сдвигается по изображению с суммированием произведений. Обладает свойством коммутативности/ассоциативности.
* **Корреляция (Cross-correlation):** То же самое, но ядро **не отражается**.
* **Различие:** В глубоком обучении (CNN) обычно используют термин «свёртка», но реализуют «корреляцию» (так как веса учатся, их ориентация не важна).
* *Принципиальный пример:* Если ядро симметрично (Гаусс, Лапласиан) — результат одинаков. Если ядро несимметрично (например, фильтр производной $[-1, 1]$), то свёртка и корреляция дадут результаты с противоположными знаками или сдвинутые в разные стороны.

### 7. Шумы и методы подавления
* **Гауссов шум:** Случайные отклонения яркости (тепловой шум матрицы).
    * *Борьба:* **Гауссово сглаживание** (эффективно, но мылит края), **Билатеральный фильтр** (сглаживает однородные области, но сохраняет резкие границы, учитывая разницу яркостей), **Усреднение кадров** (лучший метод для статики — шум уходит в ноль).
* **Импульсный шум («Соль и перец»):** Случайные черные и белые пиксели (битые пиксели, ошибки передачи).
    * *Борьба:* **Медианный фильтр**. Он заменяет пиксель медианой соседей, полностью удаляя выброс и сохраняя четкость границ. Гаусс здесь бесполезен (просто размажет пятно).

### 8. Выделение краев (Градиент)
Край — это резкое изменение функции яркости. Градиент $\nabla f$ указывает направление наибольшего роста яркости, а его модуль — силу края.
* **Робертс (2x2):** Диагональная разница. Очень чувствителен к шуму, используется редко.
* **Превитт / Собель (3x3):** Сочетают дифференцирование с усреднением (сглаживанием) поперек края. Собель придает больше веса центральному ряду. Более устойчивы к шуму.
* **Scharr:** Улучшенная версия Собеля. Обеспечивает лучшую «вращательную инвариантность» (одинаковый отклик на край под любым углом), так как его коэффициенты лучше аппроксимируют производную.

### 9. Компенсация освещения и Retinex
Неравномерное освещение мешает сегментации.
* **Идея Retinex:** Изображение $S(x,y)$ есть произведение Освещенности $L$ (меняется плавно) и Отражательной способности объекта $R$ (меняется резко). $S = L \times R$.
* **Алгоритм (SSR - Single Scale Retinex):** Переходим в логарифмический домен ($\ln S = \ln L + \ln R$), оцениваем $L$ сильным размытием (Гауссом) и вычитаем его.
* *Применение:* Выравнивание теней, улучшение видимости на снимках против света, обработка медицинских снимков.

### 10. Простая сегментация
* **Region Growing (Выращивание областей):** Начинаем с пикселя-зерна (seed). Добавляем соседей, если $|I_{seed} - I_{neighbor}| < \delta$.
* **Split and Merge:** Рекурсивно делим изображение на квадранты, если дисперсия яркости в них велика. Затем объединяем соседние блоки, если они похожи.
* **Роль порога $\delta$:** Это ключевой параметр.
    * Малый $\delta$: **Пересегментация** (объект дробится на куски).
    * Большой $\delta$: **Недосегментация** (объект сливается с фоном).

---

## Модуль 2. Сопоставление и классическая классификация

### 11. Задача сопоставления (Matching)
Задача состоит в нахождении соответствий между элементами (пикселями, точками, объектами) на двух или более изображениях одной и той же сцены.
* *Применения:* Создание панорам (stitching), 3D-реконструкция (стереопары), отслеживание движения (tracking), распознавание объектов по образцу.

### 12. Сложности сопоставления
1.  **Геометрические искажения:** Поворот, масштаб, изменение ракурса (аффинные/проективные искажения). *Решение:* Инвариантные дескрипторы (SIFT), пирамиды масштабов.
2.  **Фотометрические искажения:** Изменение яркости, контраста, блики. *Решение:* Нормализация дескрипторов, использование градиентов вместо сырой яркости.
3.  **Шум и качество:** Размытие, зернистость.
4.  **Повторяющиеся текстуры:** Окна здания, шахматная доска. *Решение:* Учет геометрических ограничений (RANSAC).

### 13. Пиксельные методы vs Ключевые точки
* **Пиксельные (Direct methods, SSD, SAD, Cross-Correlation):** Сравнивают шаблоны (патчи) целиком.
    * *Плюсы:* Используют всю информацию, высокая точность на малых смещениях.
    * *Минусы:* Не работают при вращении/масштабировании, чувствительны к изменению освещения. Работают, когда кадры очень похожи (видеопоток).
* **Feature-based (Ключевые точки):** Сводят изображение к набору дескрипторов особых точек.
    * *Плюсы:* Инвариантны к масштабу, повороту, перекрытиям. Быстрые (сравнивается мало данных).
    * *Минусы:* Теряют информацию на однородных областях (небо, стена).

### 14. Детектор Харриса
Основан на анализе автокорреляционной матрицы (Structure Tensor) в окрестности точки.
* **Идея:**
    * На ровном месте сдвиг окна не меняет яркость.
    * На краю (edge) яркость меняется только поперек края.
    * В **углу** яркость меняется резко при сдвиге в **любом** направлении.
* **Математика:** Если оба собственных числа матрицы ($\lambda_1, \lambda_2$) велики — это угол.
* *Устойчивость:* Хорош при поворотах и изменении яркости. Плох при изменении масштаба (угол может стать скругленным).

### 15. Blob-детекторы
В отличие от углов (пересечение границ), блобы — это области, яркость которых отличается от окружения (пятна).
* **Принцип:** Используют Лапласиан Гауссиана (LoG) или Difference of Gaussians (DoG). Это фильтр, похожий на "мексиканскую шляпу", который дает максимум отклика в центре круглого пятна определенного радиуса.
* *Пример:* SIFT использует DoG для поиска точек.

### 16. Конвейер Feature-based matching
1.  **Feature Detection:** Найти интересные точки (углы, пятна). Пример: Harris, FAST.
2.  **Feature Description:** Описать окрестность точки вектором чисел (инвариантным к искажениям). Пример: SIFT, ORB.
3.  **Feature Matching:** Для каждого дескриптора первого кадра найти ближайшего соседа во втором (Euclidean distance, Hamming distance).
4.  **Outlier Rejection:** Отбросить явные ошибки (Lowe's ratio test: лучший сосед должен быть намного ближе второго по похожести).
5.  **Motion Estimation:** Найти матрицу преобразования (обычно с RANSAC).

### 17. Метод SIFT (Scale-Invariant Feature Transform)
Классический, очень надежный алгоритм.
* **Масштаб:** Ищет экстремумы в пирамиде DoG (разные размытия), автоматически определяя масштаб пятна.
* **Поворот:** Вычисляет доминирующее направление градиента вокруг точки и поворачивает дескриптор относительно него.
* **Дескриптор:** Строит гистограммы градиентов в сетке 4x4 вокруг точки (всего 128 чисел). Это дает устойчивость к малым геометрическим деформациям.

### 18. RANSAC (Random Sample Consensus)
Алгоритм для оценки параметров модели в условиях сильного шума (выбросов).
* **Зачем:** Обычный МНК (метод наименьших квадратов) сломается даже от одного грубого выброса.
* **Принцип:**
    1. Взять минимально возможное число точек (случайно).
    2. Построить по ним модель.
    3. Проверить, сколько остальных точек подходят под эту модель (inliers).
    4. Повторить много раз. Выбрать модель с максимальным числом inliers.

### 19. Выбор модели (2D vs 3D)
* **2D (Гомография, Аффинное):** Связывает точки плоскости. Применимо, если снимаем плоский объект (картину) ИЛИ если камера только вращается вокруг своей оси (панорама).
* **3D (Фундаментальная матрица):** Учитывает эпиполярную геометрию. Требуется, когда камера перемещается поступательно (трансляция) и сцена объемная.
* *Признак нехватки 2D:* При попытке склеить панораму ближние объекты двоятся, не совпадая с дальним фоном (параллакс).

### 20. "Мешок слов" (Bag of Visual Words)
Метод классификации/поиска, пришедший из анализа текстов.
1.  Извлекаем дескрипторы со всех картинок.
2.  Кластеризуем их (K-means) — центры кластеров становятся "словами" словаря.
3.  Каждое изображение описываем гистограммой: сколько раз встретилось каждое "слово".
* *Плюс:* Фиксированная длина вектора, скорость.
* *Минус:* Полная потеря информации о расположении. Перемешанные фрагменты картинки дадут тот же вектор.

### 21. Пространственная пирамида (Spatial Pyramid)
Решение проблемы "Мешка слов".
* Делим изображение на уровни: 1x1 (всё фото), 2x2, 4x4.
* Считаем гистограммы слов для каждой ячейки и конкатенируем их.
* Это добавляет грубую информацию о структуре (например, "много текстуры неба в верхней части").

### 22. HOG и LBP
* **HOG (Histogram of Oriented Gradients):** Делит фото на ячейки, в каждой строит гистограмму направлений градиентов.
    * *Сила:* Отлично описывает форму и силуэт. Стандарт для детекции пешеходов (до эры глубокого обучения).
* **LBP (Local Binary Patterns):** Сравнивает пиксель с соседями (больше/меньше) и записывает результат как бинарный код.
    * *Сила:* Кодирует микротекстуру. Отлично работает для распознавания лиц и классификации текстур, устойчив к монотонному изменению яркости.

---

## Модуль 3. Нейросетевые методы

### 23. Нейрон и перцептрон
* **Нейрон:** $y = f(\sum w_i x_i + b)$. Веса $w$ определяют важность входов, $b$ (смещение) сдвигает порог активации.
* **Проблема XOR:** Один перцептрон строит **линейную** разделяющую поверхность (гиперплоскость). Задачи типа XOR (где объекты одного класса лежат по диагонали) линейно неразделимы. Нужно минимум два слоя.

### 24. Обучение: Backprop и оптимизаторы
* **Backpropagation:** Метод вычисления градиента ошибки по весам (chain rule), чтобы знать, куда крутить веса для уменьшения ошибки.
* **Оптимизаторы:**
    * **SGD:** Простой спуск по градиенту. Может "блуждать" или застревать в седловых точках.
    * **Momentum:** Добавляет инерцию. Помогает проскакивать мелкие ямки и быстрее двигаться в нужном направлении.
    * **Adam:** Адаптивно подбирает шаг обучения (learning rate) для каждого параметра отдельно + использует Momentum. Обычно работает лучше и быстрее «из коробки».

### 25. Функции активации и потерь
* **Активация:** Нужна для внесения нелинейности (иначе сеть = линейная регрессия).
    * *Классификация:* На выходе **Softmax** (превращает выходы в вероятности, сумма=1).
* **Функция потерь (Loss):**
    * *MSE (Mean Squared Error):* Подходит для регрессии. В классификации обучается медленно при больших ошибках (из-за малых градиентов сигмоиды/софтмакса на хвостах).
    * *Cross-Entropy:* Напрямую штрафует за расхождение распределений вероятностей. Дает сильный градиент, если модель уверенно предсказывает неверный класс.

### 26. CNN: Почему свёртки?
Для изображений полносвязные сети (MLP) неэффективны (слишком много весов, теряется структура).
* **Локальность:** Пиксели коррелируют с соседями. Свёртка смотрит на локальные паттерны.
* **Разделение весов (Weight Sharing):** Один и тот же фильтр (например, детектор вертикальной линии) применяется ко всему изображению. Это дает инвариантность к сдвигу (translation invariance).
* **Pooling/Stride:** Уменьшают размерность карты признаков, увеличивая «поле восприятия» (receptive field) следующих слоев и снижая вычислительную сложность.

### 27. Выход слоя как вектор-признак (Embedding)
Сверточная часть сети превращает картинку в компактный вектор (эмбеддинг).
* (а) **Классификация:** Вектор подается на полносвязный слой (классификатор), который разделяет пространство гиперплоскостями.
* (б) **Поиск (Retrieval):** Векторы сравниваются через косинусное расстояние или L2. Похожие картинки $\approx$ близкие векторы. Обучается через Triplet Loss или Contrastive Loss.

### 28. Визуализация нейросетей
* **Что дает:** Понимание, на что опирается сеть (не переобучилась ли она на фон/водяной знак?).
* **Инструменты:**
    * *Визуализация фильтров:* Показывает, какие паттерны ищет слой (грани, глаза, колеса).
    * *Карты активации (Saliency maps, Grad-CAM):* Тепловая карта поверх фото, показывающая наиболее важные области для принятия решения.
    * *TensorBoard:* Отслеживание динамики Loss, весов и метрик в реальном времени.

### 29. UMAP vs t-SNE vs PCA
Методы снижения размерности (например, 512D -> 2D) для визуализации данных.
* **PCA:** Линейный метод. Хорош для простых данных, сохраняет глобальную дисперсию. Плох для сложной кластерной структуры.
* **t-SNE:** Нелинейный. Отлично группирует похожие объекты в кластеры, но расстояние *между* кластерами не имеет смысла. Очень медленный на больших данных.
* **UMAP:** Быстрее t-SNE, лучше сохраняет **глобальную структуру** (топологию) данных, то есть расстояния между кластерами более информативны.

### 30. Fine-tuning (Дообучение)
* **Суть:** Берем сеть, обученную на ImageNet, и доучиваем на своих данных.
* **Заморозка:** Первые слои (выделяют базовые примитивы: линии, углы) обычно замораживают, так как они универсальны. Учат только последние слои (высокоуровневые признаки) и классификатор.
* **Риски:** Переобучение (если данных мало, а разморозили много слоев), Catastrophic Forgetting (сеть забывает старые знания, если учить слишком агрессивно).

### 31. Архитектурные идеи
* **Inception:** Идея «расширения» вместо углубления. В одном блоке параллельно работают свертки 1x1, 3x3, 5x5. Сеть сама решает, какой размер фильтра важен для текущего признака.
* **MobileNet:** Идея **Depthwise Separable Convolution**. Стандартная свертка делает (пространство + каналы) одновременно. MobileNet делит это на 2 шага: 1) свертка по пространству для каждого канала отдельно, 2) свертка 1x1 для смешивания каналов. Это в разы снижает число операций.

### 32. Оптический поток (Optical Flow)
Векторное поле, показывающее, куда сместился каждый пиксель между кадрами $t$ и $t+1$.
* **Проблемы:**
    * *Aperture problem:* Глядя через узкую щель на движущуюся стену, нельзя понять истинное направление движения.
    * *Освещение:* Классика предполагает $I(x,y,t) = I(x+dx, y+dy, t+dt)$ (постоянство яркости). Тень ломает этот принцип.
* **Методы:**
    * *Lucas-Kanade:* Решает задачу локально (в окне), предполагая, что все пиксели окна движутся одинаково.
    * *Horn-Schunck:* Глобальный метод, добавляет штраф за негладкость поля скоростей.
    * *Нейросети (FlowNet, RAFT):* Учат предсказывать поток напрямую, лучше справляются с большими смещениями и текстурами.

### 33. Multiple Object Tracking (MOT)
* **Схема:** Tracking-by-detection.
    1. Детектор находит объекты на текущем кадре.
    2. Алгоритм (например, Венгерский) сопоставляет новые детекции с существующими треками (по IoU или внешнему виду).
* **Метрики:** MOTA (точность), IDF1 (способность удерживать ID объекта без переключений).
* **SORT (Simple Online and Realtime Tracking):** Использует Фильтр Калмана для предсказания движения боксов. Если предсказание совпадает с новой детекцией — это тот же объект. Это позволяет продолжать трек, даже если детектор пропустил объект на 1-2 кадра.

---

## Модуль 4. Детектирование, сегментация, 3D

### 34. Детектирование объектов
Задача сложнее классификации, так как нужно определить **что** (класс) и **где** (координаты рамки).
* Выход сети: не просто вектор вероятностей, а набор векторов: `[P_class, x, y, w, h]`.

### 35. IoU (Intersection over Union)
Мера качества перекрытия двух рамок (предсказанной и истинной).
$$IoU = \frac{\text{Площадь пересечения}}{\text{Площадь объединения}}$$
* **Порог 0.5:** Общепринятый критерий «попадания». Если IoU > 0.5, считаем детекцию верной (True Positive). Повышение порога (0.75, 0.9) требует от детектора идеальной точности границ.

### 36. Метрики детектора (Precision, Recall, mAP)
* **Precision (Точность):** Какая доля из найденных объектов — реальные (не ложные срабатывания).
* **Recall (Полнота):** Какую долю реальных объектов мы нашли.
* **PR-кривая:** График Precision от Recall при изменении порога уверенности (confidence threshold).
* **mAP (mean Average Precision):** Площадь под PR-кривой, усредненная по всем классам. Это «золотой стандарт» оценки детекторов.

### 37. NMS (Non-Maximum Suppression)
Детекторы часто выдают кучу дублирующих рамок вокруг одного объекта.
* **Алгоритм:**
    1. Отсортировать рамки по уверенности.
    2. Взять самую уверенную, добавить в ответ.
    3. Удалить все остальные рамки, которые сильно пересекаются с ней (IoU > порога).
    4. Повторять.
* **Soft-NMS:** Вместо жесткого удаления просто понижает уверенность перекрывающихся рамок. Помогает, если объекты действительно стоят плотно друг к другу.

### 38. HOG + SVM (Классика)
До нейросетей это был топ.
* Скользящее окно проходит по изображению. В каждом окне считается HOG-дескриптор. SVM (метод опорных векторов) решает: "пешеход" или "нет".
* *Недостатки:* Очень медленно (нужно сканировать много масштабов), ручные признаки менее выразительны, чем CNN.

### 39. Двухэтапные vs Одноэтапные детекторы
* **Two-stage (R-CNN, Faster R-CNN):**
    1. Этап Proposal: Генерация кандидатов (где *может быть* объект).
    2. Этап Refinement: Классификация и уточнение границ кандидатов.
    * *Итог:* Очень точно, но медленнее.
* **One-stage (YOLO, SSD):**
    * Смотрит на картинку один раз. Разбивает её на сетку, и каждая ячейка сетки предсказывает боксы.
    * *Итог:* Real-time скорость, но чуть хуже точность (особенно на мелких объектах).

### 40. Виды сегментации
* **Бинарная:** Отделить передний план от фона.
* **Семантическая (Semantic):** Каждому пикселю присвоить класс (дорога, небо, машина). Все машины — один класс (один цвет маски).
* **Инстанс (Instance):** Разделяет отдельные объекты одного класса (Машина №1, Машина №2). Фон обычно игнорируется.
* **Паноптическая (Panoptic):** Семантическая + Инстанс (все пиксели классифицированы + разделены объекты).

### 41. GraphCuts и Марковские случайные поля
Изображение представляется как граф, где узлы — пиксели, а ребра связывают соседей.
* **Задача:** Разрезать граф на «объект» и «фон» с минимальной «стоимостью» разреза.
* **Потенциалы:**
    * *Унарный:* Вероятность пикселя быть объектом (на основе цвета).
    * *Парный:* Штраф за разный класс у похожих соседей.
* Это обеспечивает гладкость границ (регуляризацию).

### 42. CRF (Conditional Random Fields)
Часто используется как пост-обработка после нейросети (например, в DeepLab).
* Нейросети часто дают грубые, «пухлые» маски из-за пулинга.
* CRF «притягивает» границы маски к цветовым границам (контрастным краям) исходного изображения, делая сегментацию детализированной (до волоска).

### 43. Перенос стиля (Neural Style Transfer)
Метод, позволяющий нарисовать фото в стиле Ван Гога.
* **Content Loss:** Сравнивает активации глубоких слоев сети (VGG) для контента и результата (чтобы сохранить форму домов/людей).
* **Style Loss:** Сравнивает **Матрицы Грама** (корреляции между каналами признаков) для стиля и результата. Матрица Грама кодирует текстуру и цвета, игнорируя форму.

### 44. GAN (Generative Adversarial Networks)
* **Игра:** Генератор $G$ создает подделку. Дискриминатор $D$ учится отличать подделку от реальных фото. Они обучаются совместно в конкуренции.
* **Conditional GAN (Pix2Pix):** Генерация управляется входом (раскраска ч/б фото, карта -> спутник). Требует парных данных.
* **CycleGAN:** Работает **без парных данных**. Учит превращать Лошадей в Зебр и обратно.
    * *Cycle Consistency:* $F(G(x)) \approx x$. Если превратить лошадь в зебру, а потом обратно — должна получиться та же лошадь. Это предотвращает коллапс (когда генератор рисует случайную зебру).

### 45. 3D-реконструкция
* **Разреженная (SfM - Structure from Motion):** Восстанавливает только облако ключевых точек и траекторию камеры.
* **Плотная (MVS - Multi-View Stereo):** Строит карту глубины для каждого пикселя.
* **Матрица проекции $P = K [R | t]$:**
    * $K$ — внутренние параметры (фокус, центр).
    * $R, t$ — внешние (поворот и позиция камеры в мире).
* **Эпиполярное ограничение:** Если мы знаем взаимное положение двух камер, поиск соответствия для точки $x$ сводится к поиску на одной линии (эпиполярной линии) на втором кадре, а не по всему изображению.
* **Bundle Adjustment:** Финальный шаг SfM. Глобальная оптимизация, которая минимизирует ошибку репроекции (разницу между тем, где точки видны на кадрах, и где они должны быть согласно 3D-модели), подправляя и 3D-точки, и положения камер.
